{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8246e53a-2989-4a4e-a1c5-03eea0b0c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb02df0-e9d3-4354-8785-691584c1724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f2f83-e20e-4fa0-8be9-5631835acbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.source.unique())\n",
    "print(df.target_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484ef7e-f1cd-4d17-a75e-e8d8f6a29b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Ensure the 'log_message' column exists and is of string type\n",
    "if \"log_message\" in df.columns:\n",
    "    df[\"log_message\"] = df[\"log_message\"].astype(str)  # Handle non-string entries gracefully\n",
    "    \n",
    "    # Encode text data into dense vector embeddings\n",
    "    embeddings = model.encode(df[\"log_message\"].tolist(), show_progress_bar=True, convert_to_numpy=True)\n",
    "else:\n",
    "    raise KeyError(\"Column 'log_message' not found in DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73809cc-6ec3-4e34-8b15-7e0c90fe9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89682231-6fc9-48f8-aebd-e08cdda546f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Initialize DBSCAN with cosine distance\n",
    "# Note: the correct parameter is 'metric' (not 'metrics') and 'min_samples' (not 'min_sample')\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=1, metric=\"cosine\")\n",
    "\n",
    "# Fit the DBSCAN model on the embeddings\n",
    "clusters = dbscan.fit(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e3344-a087-49f7-b2f5-e64690d7023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cluster labels to the DataFrame\n",
    "df[\"cluster\"] = clusters.labels_\n",
    "\n",
    "# Display the first few rows to inspect results\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4009dc-9c12-432f-9649-db4cd95a6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Only compute silhouette score if there are at least 2 clusters (excluding noise)\n",
    "n_clusters = len(set(clusters.labels_)) - (1 if -1 in clusters.labels_ else 0)\n",
    "\n",
    "if n_clusters > 1:\n",
    "    score = silhouette_score(embeddings, clusters.labels_, metric=\"cosine\")\n",
    "    print(f\"Silhouette Score: {score:.4f}\")\n",
    "else:\n",
    "    print(\"Silhouette score not applicable: fewer than 2 clusters found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78b6e3-0038-4c00-9db7-d5df67b591ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reduce embeddings to 2D for visualization\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine', random_state=42)\n",
    "embedding_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_df = pd.DataFrame({\n",
    "    \"x\": embedding_2d[:, 0],\n",
    "    \"y\": embedding_2d[:, 1],\n",
    "    \"cluster\": df[\"cluster\"].astype(str)  # Convert for categorical coloring\n",
    "})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=plot_df, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\", s=50, alpha=0.8)\n",
    "plt.title(\"UMAP Projection of Sentence Embeddings by Cluster\", fontsize=14)\n",
    "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32b176-e693-4d46-a1bd-fb61729e9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"cluster\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec4d06-a743-4721-ac93-2019f00cb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many entries are in each cluster\n",
    "cluster_counts = df[\"cluster\"].value_counts()\n",
    "\n",
    "# Get clusters with more than 10 samples\n",
    "large_clusters = cluster_counts[cluster_counts > 10].index\n",
    "\n",
    "# Display the top 5 log messages for each large cluster\n",
    "for cluster in large_clusters:\n",
    "    print(f\"\\n Cluster {cluster} (Size: {cluster_counts[cluster]}):\")\n",
    "    print(df[df[\"cluster\"] == cluster][\"log_message\"].head(5).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb307e-d690-41f1-9cb0-dbe541bf029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify_with_regex(log_message):\n",
    "    \"\"\"\n",
    "    Classifies a log message using regex patterns to determine its category.\n",
    "    Returns a string label if matched, otherwise None.\n",
    "    \"\"\"\n",
    "    regex_patterns = {\n",
    "        r\"User User\\d+ logged (in|out)\\.\": \"User Action\",\n",
    "        r\"Backup (started|ended) at .*\": \"System Notification\",\n",
    "        r\"Backup completed successfully\\.\": \"System Notification\",\n",
    "        r\"System Updated to version .*\": \"System Notification\",\n",
    "        r\"File .* uploaded successfully.*\": \"System Notification\",\n",
    "        r\"Disk cleanup completed successfully\\.\": \"System Notification\",\n",
    "        r\"System reboot initiated by user .*\": \"System Notification\",\n",
    "        r\"Account with ID .*\": \"User Action\"\n",
    "    }\n",
    "\n",
    "    for pattern, label in regex_patterns.items():\n",
    "        if re.search(pattern, log_message, re.IGNORECASE):\n",
    "            return label\n",
    "    return \"Unclassified\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f743b-e307-4519-9502-b47a7f1eadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regex-based classification to each log message\n",
    "df[\"regex_label\"] = df[\"log_message\"].apply(classify_with_regex)\n",
    "\n",
    "df[\"regex_label\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e325ef4-44d1-47bc-9647-36350d3ab49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract logs that were not matched by any regex pattern\n",
    "df_non_regex = df[df[\"regex_label\"] == \"Unclassified\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a5c9e-2613-4b1f-9009-21cab9b8696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rare target labels (appearing 5 times or fewer) within unmatched logs\n",
    "rare_labels = df_non_regex[\"target_label\"].value_counts()\n",
    "rare_labels = rare_labels[rare_labels <= 5].index.tolist()\n",
    "\n",
    "print(rare_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36e0e8-aca8-4fa6-93fe-440680f7153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out entries from source 'LegacyCRM'\n",
    "df_non_legacy = df_non_regex[df_non_regex[\"source\"] != \"LegacyCRM\"]\n",
    "\n",
    "# View the unique sources remaining in the filtered DataFrame\n",
    "print(df_non_legacy[\"source\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb3e06-a02c-4a15-a110-d31c925a5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the log messages from non-legacy sources using the sentence transformer\n",
    "filter_embeddings = model.encode(\n",
    "    df_non_legacy[\"log_message\"].astype(str).tolist(),\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cb762-ddbe-4745-8eee-37b811233489",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_embeddings[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d5d91d-3e00-44a6-9d28-d0d54a335db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and target labels\n",
    "X = filter_embeddings\n",
    "y = df_non_legacy[\"target_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e594d37-4d77-4a64-92ec-433611778539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa620f-8191-4491-a0dd-5ec2101d1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train a logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Display a detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b04fc-3859-48cb-8136-d2691bc47734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ensure the model directory exists\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save the trained classifier\n",
    "joblib.dump(clf, \"../models/log_classifier.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Global)",
   "language": "python",
   "name": "global-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
